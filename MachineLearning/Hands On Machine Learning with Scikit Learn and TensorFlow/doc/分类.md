# 分类

## 二分类

### 选择分类器

#### Scikit-Learn 库中有的分类算法

* SGDClassifier

### 分类性能评估

#### 使用交叉验证测量准确性

使用sklearn的cross_val_score()函数来进行k折交叉验证可以得到。最常见的用法如下：

```python
from sklearn.model_selection import cross_val_score

cross_val_score(estimator, X_train, y_train_5, cv=k, scoring="accuracy")
```

准确性通常来说不是一个好的性能度量指标，因为哪怕是很初等的分类模型都有可能有很好的准确性（尤其是在数据不平衡的条件下）。

不过由于使用交叉验证测量准确性方便快捷，所以可以作为验证模型的第一步：如果模型的准确性都很低，那么就没有做其他验证的必要了。

#### 混淆矩阵

混淆矩阵中的每一行表示一个实际的类, 而每一列表示一个预测的类。一个完美的分类器将只有真反例和真正例，所以混淆矩阵的非零值仅在其主对角线（左上至右下）。

使用sklearn的cross_val_predict()可以对数据集进行k折交叉验证。这个函数返回的是预测值而不是准确率。利用cross_val_predict()得到的预测结果，与真正的目标列进行对比，可以得到混淆矩阵。

典型的样例代码如下：

```python
from sklearn.model_selection import cross_val_predict

y_train_pred = cross_val_predict(estimator, X_train, y_train_5, cv=k)#这里得到了预测结果y_train_pred

from sklearn.metrics import confusion_matrix
confusion_matrix(y_train_5, y_train_pred)

array([[53272, 1307],
        [ 1077, 4344]])#对角线代表预测正确，非对角线代表预测错误
```

#### 准确率、召回率、F1值

准确率：正例预测的精度。

召回率：正例被分类器正确探测出的比率。

F1值：准确率和召回率的调和平均。

典型的样例代码如下：

```python
from sklearn.metrics import precision_score, recall_score, f1_score

precision_score(y_train_5, y_train_pred)# 计算准确率。y_train_pred来自于cross_val_predict（）,下同

recall_score(y_train_5, y_train_pred) # 计算召回率。

f1_score(y_train_5, y_train_pred) # 计算F1值
```

F1 支持那些有着相近准确率和召回率的分类器。这不会总是你想要的。有的场景你会绝大程度地关心准确率，而另外一些场景你会更关心召回率。举例子，如果你训练一个分类器去检测视频是否适合儿童观看，你会倾向选择那种即便拒绝了很多好视频、但保证所保留的视频都是好（高准确率）的分类器，而不是那种高召回率、但让坏视频混入的分类器（这种情况下你或许想增加人工去检测分类器选择出来的视频）。另一方面，加入你训练一个分类器去检测监控图像当中的窃贼，有着 30% 准确率、99% 召回率的分类器或许是合适的（当然，警卫会得到一些错误的报警，但是几乎所有的窃贼都会被抓到）。

不幸的是，你不能同时拥有两者。增加准确率会降低召回率，反之亦然。这叫做准确率与召回率之间的折衷。

#### 准确率/召回率之间的折衷

TODO

#### ROC曲线

TODO

## 多分类

### 多分类策略

一些算法（比如随机森林分类器或者朴素贝叶斯分类器）可以直接处理多类分类问题。其他一些算法（比如 SVM 分类器或者线性分类器）则是严格的二分类器。然后，有许多策略可以让你用二分类器去执行多类分类。

举例子，创建一个可以将图片分成 10 类（从 0 到 9）的系统的一个方法是：训练10个二分类器，每一个对应一个数字（探测器 0，探测器 1，探测器 2，以此类推）。然后当你想对某张图片进行分类的时候，让每一个分类器对这个图片进行分类，选出决策分数最高的那个分类器。这叫做“一对所有”（OvA）策略（也被叫做“一对其他”）。

另一个策略是对每一对数字都训练一个二分类器：一个分类器用来处理数字 0 和数字 1，一个用来处理数字 0 和数字 2，一个用来处理数字 1 和 2，以此类推。这叫做“一对一”（OvO）策略。如果有 N 个类。你需要训练N*(N-1)/2个分类器。然后看哪个类胜出。OvO 策略的主要优点是：每个分类器只需要在训练集的部分数据上面进行训练。这部分数据是它所需要区分的那两个类对应的数据。

一些算法（比如 SVM 分类器）在训练集的大小上很难扩展，所以对于这些算法，OvO 是比较好的，因为它可以在小的数据集上面可以更多地训练，较之于巨大的数据集而言。但是，对于大部分的二分类器来说，OvA 是更好的选择。

Scikit-Learn 可以探测出你想使用一个二分类器去完成多分类的任务，它会自动地执行 OvA（除了 SVM 分类器，它使用 OvO）。

TODO

### 误差分析

混淆矩阵是最常见的误差分析工具。

## 多标签分类

到目前为止，所有的样例都总是被分配到仅一个类。有些情况下，你也许想让你的分类器给一个样例输出多个类别。

比如说，思考一个人脸识别器。如果对于同一张图片，它识别出几个人，它应该做什么？当然它应该给每一个它识别出的人贴上一个标签。比方说，这个分类器被训练成识别三个人脸，Alice，Bob，Charlie；然后当它被输入一张含有 Alice 和 Bob 的图片，它应该输出[1, 0, 1]（意思是：Alice 是，Bob 不是，Charlie 是）。

这种输出多个二值标签的分类系统被叫做多标签分类系统。

目前暂时没有实际的需求，等遇到了再说吧。

## 多输出分类

我们即将讨论的最后一种分类任务被叫做“多输出-多类分类”（或者简称为多输出分类）。

它是多标签分类的简单泛化，在这里每一个标签可以是多类别的（比如说，它可以有多于两个可能值）。

目前暂时没有实际的需求，等遇到了再说吧。
